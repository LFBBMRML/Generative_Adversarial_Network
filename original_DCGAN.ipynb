{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBh5P1TxLBZIG74P8T2JxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LFBBMRML/Generative_Adversarial_Network/blob/main/original_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJdKJSnldUOf"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "tf.__version__\r\n",
        "%load_ext tensorboard\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from numpy import expand_dims\r\n",
        "from numpy import zeros\r\n",
        "from numpy import ones\r\n",
        "from numpy import vstack\r\n",
        "from numpy.random import randn\r\n",
        "from numpy.random import randint\r\n",
        "from keras import optimizers\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import Conv2DTranspose\r\n",
        "from keras.layers import LeakyReLU\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.models import load_model\r\n",
        "from google.colab import files\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import datetime\r\n",
        "import time as zeit\r\n",
        "from datetime import time\r\n",
        "\r\n",
        "from keras import layers\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYrUNdOQforE"
      },
      "source": [
        "def define_discriminator(in_shape=(32, 32, 3)):\r\n",
        "  D = Sequential()\r\n",
        "\r\n",
        "  D.add(Conv2D(64, (3, 3), padding = 'same', input_shape=in_shape))\r\n",
        "  D.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  D.add(Conv2D(128, (3, 3), strides=(2,2), padding='same'))\r\n",
        "  D.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  D.add(Conv2D(128, (3, 3), strides=(2,2), padding = 'same'))\r\n",
        "  D.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  D.add(Conv2D(256, (3, 3), strides=(2,2), padding = 'same'))\r\n",
        "  D.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  D.add(Flatten())\r\n",
        "  D.add(Dropout(0.4))\r\n",
        "  D.add(Dense(1, activation = 'sigmoid'))\r\n",
        "\r\n",
        "  opt = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\r\n",
        "  D.compile(loss='binary_crossentropy', optimizer=opt, metrics = ['accuracy'])\r\n",
        "\r\n",
        "  return D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-YJQJ17z36V"
      },
      "source": [
        "def define_generator(latent_dim):\r\n",
        "  G = Sequential()\r\n",
        "\r\n",
        "  G.add(Dense(256 * 4 * 4, input_dim=latent_dim))\r\n",
        "  G.add(LeakyReLU(alpha=0.2))\r\n",
        "  G.add(layers.Reshape((4, 4, 256)))\r\n",
        "\r\n",
        "  G.add(Conv2DTranspose(128, (4, 4), strides=(2,2), padding='same'))\r\n",
        "  G.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  G.add(Conv2DTranspose(128, (4, 4), strides=(2,2), padding='same'))\r\n",
        "  G.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  G.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\r\n",
        "  G.add(LeakyReLU(alpha=0.2))\r\n",
        "\r\n",
        "  G.add(Conv2D(3, (3 ,3), activation='tanh', padding='same'))\r\n",
        "  \r\n",
        "  return G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQs1UHBF4kbD"
      },
      "source": [
        "def define_gan(g_model, d_model):\r\n",
        "  d_model.trainable = False\r\n",
        "\r\n",
        "  model = Sequential()\r\n",
        "  model.add(g_model)\r\n",
        "  model.add(d_model)\r\n",
        "\r\n",
        "  opt = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\r\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer=opt)\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sTIIiFZ6J0_"
      },
      "source": [
        "def load_real_samples():\r\n",
        "  (train, _), (_,_) = tf.keras.datasets.cifar10.load_data()\r\n",
        "  images = train.astype('float32')\r\n",
        "  images = (images - 127.5) / 127.5\r\n",
        "  return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IigvzPZ5o2u"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\r\n",
        "  ix = randint(0, dataset.shape[0], n_samples)\r\n",
        "  X = dataset[ix]\r\n",
        "  y = ones((n_samples, 1))\r\n",
        "\r\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxdJW0wH6DAU"
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\r\n",
        "  x_input = randn(latent_dim * n_samples)\r\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\r\n",
        "  return x_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrYzGRtF7tUr"
      },
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\r\n",
        "  x_input = generate_latent_points(latent_dim, n_samples)\r\n",
        "  X = g_model.predict(x_input)\r\n",
        "  y = zeros((n_samples, 1))\r\n",
        "  return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlGBuEre8Ocy"
      },
      "source": [
        "def save_plot(examples, epoch, n=6):\r\n",
        "  examples = (examples + 1) / 2.0\r\n",
        "\r\n",
        "  for i in range(n*n):\r\n",
        "    plt.subplot(n, n, i+1)\r\n",
        "    plt.axis('off')\r\n",
        "    plt.imshow(examples[i])\r\n",
        "  filename_plot = 'generated_plot_e%03d.png' % (epoch+1)\r\n",
        "  plt.savefig(filename_plot)\r\n",
        "  #files.download(filename_plot)\r\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upBnpQML96i7"
      },
      "source": [
        "def summarize_performance(epoch, gan_model, g_model, d_model, dataset, latent_dim, n_samples=150):\r\n",
        "  X_real, y_real = generate_real_samples(dataset, n_samples)\r\n",
        "  _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\r\n",
        "\r\n",
        "  X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\r\n",
        "  _, acc_fake = d_model.evaluate(X_fake, y_fake, verbose=0)\r\n",
        "\r\n",
        "  print('>Accuracy real: %.0f%%, fake:%.0f%%' % (acc_real*100, acc_fake*100))\r\n",
        "\r\n",
        "  save_plot(X_fake, epoch)  \r\n",
        "  filename = 'Modell_Daten_%03d.h5' % (epoch+1)\r\n",
        "  g_model.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkLLM5m8_Vsm"
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64):\r\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\r\n",
        "  half_batch = int(n_batch/2)\r\n",
        "  ges_time = []\r\n",
        "  \r\n",
        "\r\n",
        "  for i in range(n_epochs):\r\n",
        "    start = zeit.time()\r\n",
        "    for j in range(bat_per_epo):\r\n",
        "      X_real, y_real = generate_real_samples(dataset, half_batch)\r\n",
        "      d_loss1, _ = d_model.train_on_batch(X_real, y_real)\r\n",
        "\r\n",
        "      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\r\n",
        "      d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\r\n",
        "\r\n",
        "      X_gan = generate_latent_points(latent_dim, n_batch)\r\n",
        "      y_gan = ones((n_batch, 1))\r\n",
        "      g_loss = gan_model.train_on_batch(X_gan, y_gan)\r\n",
        "\r\n",
        "      #print('>%d, %d/%d, d1=%.3f, d2=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\r\n",
        "      #plot_model(d_model, to_file='original_Diskriminator.png', show_shapes=True, show_layer_names=True, rankdir='TB')\r\n",
        "      #plot_model(g_model, to_file='original_Generator.png', show_shapes=True, show_layer_names=True, rankdir='TB')\r\n",
        "      #plot_model(gan_model, to_file='original_GAN_Modell.png', show_shapes=True, show_layer_names=True, rankdir='TB')\r\n",
        "    \r\n",
        "    ges_time.append(zeit.time()-start)\r\n",
        "    minuten = int((sum(ges_time))/60)\r\n",
        "    sec = sum(ges_time)%60\r\n",
        "\r\n",
        "    if (i+1) % 1 == 0:\r\n",
        "      summarize_performance(i, gan_model, g_model, d_model, dataset, latent_dim)\r\n",
        "    print(\"Die gesamte Dauer beträgt: \" + str(minuten) + \" Minuten und \" + str(sec) + \" Sekunde, für \" + str(i+1) + \" Epochen \")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xamHRXds6qxj"
      },
      "source": [
        "latent_dim = 100\r\n",
        "d_model = define_discriminator()\r\n",
        "g_model = define_generator(latent_dim)\r\n",
        "gan_model = define_gan(g_model, d_model)\r\n",
        "dataset = load_real_samples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNyYazmCufv"
      },
      "source": [
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}